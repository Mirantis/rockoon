#connection_recycle_time is set to 300sec in order not to hit into conntrack timeouts (PRODX-1179, PRODX-1170)
# Optimized for the following cloud configuration
# controllers: >=3
# computes: <=100
features:
  messaging:
    components_with_dedicated_messaging:
      - compute
      - networking
services:
  messaging:
    rabbitmq:
      values:
        conf:
          rabbitmq:
            num_acceptors.tcp: 20
            channel_max: 16
            reverse_dns_lookups: false
            vm_memory_high_watermark.relative: 0.5
        pod:
          env:
            server:
              RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "+S 6:6 +IOt 3 +Q 131070 +P 2000000"
  redis:
    redisfailover:
      redis:
        replicas: 3
      sentinel:
        replicas: 3
  database:
    mariadb:
      values:
        pod:
          lifecycle:
            disruption_budget:
              mariadb:
                min_available: 2
        conf:
          database:
            99_force: |
              [mysqld]
              datadir=/var/lib/mysql
              tmpdir=/tmp
              innodb_buffer_pool_size=10240M
          ingress_conf:
            proxy-buffer-size: "20m"
            proxy-connect-timeout: "600"
          phy_backup:
            backup_timeout: 14400
        volume:
          phy_backup:
            size: "80Gi"
  descheduler:
    descheduler:
      values:
        pod:
          resources:
            jobs:
              descheduler:
                requests:
                  memory: "1Gi"
                limits:
                  memory: "2Gi"
  ingress:
    ingress:
      values:
        pod:
          replicas:
            ingress: 3
  identity:
    keystone:
      values:
        pod:
          replicas:
            api: 15
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
        conf:
          keystone:
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
  key-manager:
    barbican:
      values:
        pod:
          replicas:
            api: 4
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
  image:
    glance:
      values:
        pod:
          replicas:
            api: 3
            registry: 3
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
              registry:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 0
        conf:
          glance:
            DEFAULT:
              workers: 8
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
  compute:
    rabbitmq:
      values:
        conf:
          rabbitmq:
            num_acceptors.tcp: 30
            channel_max: 16
            reverse_dns_lookups: false
            vm_memory_high_watermark.relative: 0.5
        pod:
          env:
            server:
              RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "+S 6:6 +IOt 3 +Q 131070 +P 2000000"
    nova:
      values:
        pod:
          replicas:
            api_metadata: 3
            osapi: 15
            conductor: 3
            consoleauth: 3
            scheduler: 7
            novncproxy: 3
            spiceproxy: 3
            placement: 4
            # Byggy code, give up and use 1 instance
            compute_ironic: 1
          lifecycle:
            disruption_budget:
              metadata:
                min_available: 2
              placement:
                min_available: 2
              osapi:
                min_available: 2
            upgrades:
              daemonsets:
                pod_replacement_strategy: RollingUpdate
                compute:
                  # upgrade computes in butches with 10% of hosts from maximum
                  max_unavailable: 10%
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 0
        conf:
          nova:
            DEFAULT:
              metadata_workers: 8
              osapi_compute_workers: 8
              block_device_allocate_retries: 600
              block_device_allocate_retries_interval: 10
              report_interval: 30
              service_down_time: 180
              rpc_response_timeout: 60
            api_database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            cell0_database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            placement_database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            conductor:
              workers: 8
            scheduler:
              workers: 1
            neutron:
              timeout: 300
            filter_scheduler:
              host_subset_size: 3
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
  networking:
    neutron:
      values:
        pod:
          replicas:
            server: 12
          lifecycle:
            disruption_budget:
              server:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
              daemonsets:
                pod_replacement_strategy: RollingUpdate
                dhcp_agent:
                  max_unavailable: 10%
                l3_agent:
                  max_unavailable: 1
                  pod_replacement_strategy: OnDelete
                lb_agent:
                  max_unavailable: 10%
                metadata_agent:
                  max_unavailable: 10%
                ovs_agent:
                  max_unavailable: 10%
                sriov_agent:
                  max_unavailable: 10%
                netns_cleanup_cron:
                  max_unavailable: 100%
        conf:
          neutron:
            DEFAULT:
              dhcp_lease_duration: 86400
              rpc_workers: 16
              api_workers: 16
              rpc_state_report_workers: 4
              agent_down_time: 190
              max_l3_agents_per_router: 2
              executor_thread_pool_size: 70
              rpc_conn_pool_size: 80
            agent:
              report_interval: 60
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 70
              connection_recycle_time: 300
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
          plugins:
            ml2_conf:
              ml2_type_vxlan:
                vni_ranges: 1:65535
            openvswitch_agent:
              oslo_messaging_rabbit:
                rpc_conn_pool_size: 30
              ovs:
                of_connect_timeout: 300
                of_inactivity_probe: 30
                of_request_timeout: 300
                ovsdb_timeout: 30
    openvswitch:
      values:
        pod:
          lifecycle:
            upgrades:
              daemonsets:
                ovn_controller:
                  enabled: true
                  pod_replacement_strategy: OnDelete
                  max_unavailable: 1
                ovs_vswitchd:
                  enabled: true
                  pod_replacement_strategy: OnDelete
                  max_unavailable: 1
    rabbitmq:
      values:
        conf:
          rabbitmq:
            num_acceptors.tcp: 50
            channel_max: 16
            reverse_dns_lookups: false
            vm_memory_high_watermark.relative: 0.8
        pod:
          env:
            server:
              RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "+S 12:12 +IOt 5 +Q 131070 +P 2000000"
  block-storage:
    cinder:
      values:
        pod:
          replicas:
            api: 4
            scheduler: 3
            volume: 6
            backup: 3
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
        conf:
          cinder:
            DEFAULT:
              rpc_response_timeout: 3600
              osapi_volume_workers: 4
              backup_workers: 6
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
  orchestration:
    heat:
      values:
        pod:
          replicas:
            cfn: 3
            api: 3
            engine: 15
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
              cfn:
                min_available: 2
              cloudwatch:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
        conf:
          heat:
            DEFAULT:
              rpc_response_timeout: 600
              num_engine_workers: 6
              max_resources_per_stack: '20000'
              max_template_size: '5440000'
              max_json_body_size: '10880000'
            heat_api:
              workers: 4
            heat_api_cfn:
              workers: 1
            heat_api_cloudwatch:
              workers: 4
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
  placement:
    placement:
      values:
        pod:
          replicas:
            api: 4
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
  load-balancer:
    octavia:
      values:
        pod:
          replicas:
            api: 3
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 0
              daemonsets:
                pod_replacement_strategy: RollingUpdate
                health_manager:
                  max_unavailable: 10%
        conf:
          software:
            apache2:
              processes: 5
          octavia:
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
            controller_worker:
              amp_active_retries: 100
              amp_active_wait_sec: 4
              workers: 8
            haproxy_amphora:
              connection_max_retries: 1500
              connection_retry_interval: 1
              rest_request_conn_timeout: 10
              rest_request_read_timeout: 120
            task_flow:
              engine: parallel
              max_workers: 4
            house_keeping:
              amphora_expiry_age: 3600
              load_balancer_expiry_age: 3600
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
  shared-file-system:
    manila:
      values:
        pod:
          replicas:
            api: 3
            scheduler: 3
            share: 3
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
        conf:
          manila:
            DEFAULT:
              rpc_response_timeout: 3600
              osapi_share_workers: 4
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
            oslo_messaging_rabbit:
              rabbit_qos_prefetch_count: 64
  dns:
    designate:
      values:
        pod:
          replicas:
            api: 12
            central: 3
            mdns: 3
            producer: 3
            sink: 3
            worker: 3
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
              registry:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
        conf:
          apache_wsgi:
            config:
              processes: 4
          designate:
            service:api:
              workers: 4
            service:central:
              workers: 16
            service:mdns:
              workers: 16
            service:producer:
              workers: 16
            service:sink:
              workers: 16
            service:worker:
              workers: 16
  dashboard:
    horizon:
      values:
        pod:
          replicas:
            server: 5
          lifecycle:
            disruption_budget:
              horizon:
                min_available: 2
            upgrades:
              deployments:
                pod_replacement_strategy: RollingUpdate
                rolling_update:
                  max_unavailable: 10%
                  max_surge: 10%
        conf:
          software:
            apache2:
              processes: 3
              threads: 10
  baremetal:
    ironic:
      values:
        pod:
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
          replicas:
            api: 5
            conductor: 3
        conf:
          ironic:
            database:
              max_pool_size: 10
              max_retries: -1
              max_overflow: 30
              connection_recycle_time: 300
  alarming:
    aodh:
      values:
        pod:
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
          replicas:
            api: 5
            evaluator: 5
            listener: 5
            notifier: 5
        conf:
          aodh:
            database:
              connection_recycle_time: 300
              max_overflow: 30
              max_pool_size: 10
  metric:
    gnocchi:
      values:
        pod:
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
          replicas:
            api: 5
        conf:
          gnocchi:
            database:
              connection_recycle_time: 300
              max_overflow: 30
              max_pool_size: 10
          software:
            apache2:
              processes: 8
  event:
    panko:
      values:
        pod:
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
          replicas:
            api: 5
  metering:
    ceilometer:
      values:
        pod:
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
          replicas:
            central: 5
            collector: 5
            notification: 5
  tempest:
    tempest:
      values:
        conf:
          tempest:
            compute:
              min_compute_nodes: 2
  memcached:
    memcached:
      values:
        conf:
          memcached:
            max_connections: 32768
  instance-ha:
    masakari:
      values:
        pod:
          replicas:
            api: 5
            engine: 5
          lifecycle:
            disruption_budget:
              api:
                min_available: 2
              engine:
                min_available: 2

timeouts:
  application_readiness:
    mariadb:
      timeout: 2400
      delay: 15
    nova:
      timeout: 2400
      delay: 15
    neutron:
      timeout: 2400
      delay: 15
    openvswitch:
      timeout: 2400
      delay: 15
